# Feature Engineering: Bibliotecas, T√©cnicas e Recursos

**Data de Atualiza√ß√£o:** 30 de Outubro de 2025  
**Fonte:** Busca intensiva

Este documento cont√©m uma cole√ß√£o abrangente de recursos sobre Feature Engineering, incluindo bibliotecas, t√©cnicas de extra√ß√£o, sele√ß√£o e transforma√ß√£o de features, al√©m de m√©todos de redu√ß√£o de dimensionalidade.

---

## üìã √çndice

- [Bibliotecas de Feature Engineering](#bibliotecas-de-feature-engineering)
- [T√©cnicas de Sele√ß√£o de Features](#t√©cnicas-de-sele√ß√£o-de-features)
- [Redu√ß√£o de Dimensionalidade](#redu√ß√£o-de-dimensionalidade)
- [Feature Importance](#feature-importance)
- [Conceitos Fundamentais](#conceitos-fundamentais)

---

## Bibliotecas de Feature Engineering

### scikit-learn Feature Extraction
- **URL:** [https://scikit-learn.org/stable/modules/feature_extraction.html](https://scikit-learn.org/stable/modules/feature_extraction.html)
- **Tipo:** M√≥dulo de Biblioteca
- **Descri√ß√£o:** M√≥dulo para extrair features de datasets em formatos suportados por algoritmos de ML. O m√≥dulo sklearn.feature_extraction pode ser usado para extrair features em um formato suportado por algoritmos de machine learning a partir de datasets consistindo de formatos como texto e imagem.

**Principais Funcionalidades:**
- **DictVectorizer:** Converte dicion√°rios de features em arrays NumPy
- **FeatureHasher:** Implementa feature hashing para vetoriza√ß√£o de alta velocidade
- **Text Feature Extraction:** Extra√ß√£o de features de texto
  - CountVectorizer: Bag of Words
  - TfidfVectorizer: TF-IDF
  - HashingVectorizer: Hashing trick
- **Image Feature Extraction:** Extra√ß√£o de patches de imagens

**Aplica√ß√µes:**
- Pr√©-processamento de texto
- Vetoriza√ß√£o de dados categ√≥ricos
- Extra√ß√£o de features de imagens

---

### Feature-engine
- **URL:** [https://github.com/feature-engine/feature_engine](https://github.com/feature-engine/feature_engine)
- **Tipo:** Biblioteca Python
- **Descri√ß√£o:** Biblioteca Python com m√∫ltiplos transformadores para engenharia e sele√ß√£o de features para uso em modelos de machine learning. Feature-engine √© uma biblioteca Python com m√∫ltiplos transformadores para engenharia e sele√ß√£o de features.

**Principais Transformadores:**
- **Missing Data Imputation:** Imputa√ß√£o de dados faltantes
- **Categorical Encoding:** Codifica√ß√£o de vari√°veis categ√≥ricas
- **Discretisation:** Discretiza√ß√£o de vari√°veis cont√≠nuas
- **Outlier Handling:** Tratamento de outliers
- **Variable Transformation:** Transforma√ß√£o de vari√°veis
- **Feature Selection:** Sele√ß√£o de features

**Vantagens:**
- Compat√≠vel com scikit-learn pipelines
- F√°cil de usar
- Bem documentado
- C√≥digo aberto

---

### Featuretools
- **URL:** [https://featuretools.alteryx.com/](https://featuretools.alteryx.com/)
- **Tipo:** Framework
- **Descri√ß√£o:** Framework para realizar engenharia de features automatizada, se destacando em datasets temporais e relacionais. Featuretools √© um framework para realizar automated feature engineering, excelling em transformar datasets temporais e relacionais em matrizes de features para machine learning.

**Conceitos Principais:**
- **Deep Feature Synthesis (DFS):** Algoritmo para criar features automaticamente
- **Entities:** Tabelas de dados
- **Relationships:** Rela√ß√µes entre tabelas
- **Primitives:** Opera√ß√µes b√°sicas de transforma√ß√£o e agrega√ß√£o

**Aplica√ß√µes:**
- Automated feature engineering
- Dados temporais
- Dados relacionais
- Redu√ß√£o de tempo de desenvolvimento

**Exemplo de Uso:**
```python
import featuretools as ft

# Criar entityset
es = ft.EntitySet(id="customers")

# Adicionar entidades
es = es.add_dataframe(dataframe_name="customers", dataframe=customers_df, index="customer_id")
es = es.add_dataframe(dataframe_name="transactions", dataframe=transactions_df, index="transaction_id", time_index="transaction_time")

# Adicionar relacionamento
es = es.add_relationship("customers", "customer_id", "transactions", "customer_id")

# Executar DFS
feature_matrix, feature_defs = ft.dfs(entityset=es, target_dataframe_name="customers")
```

---

## T√©cnicas de Sele√ß√£o de Features

### SHAP (SHapley Additive exPlanations)
- **URL:** [https://github.com/slundberg/shap](https://github.com/slundberg/shap)
- **Tipo:** Biblioteca Python
- **Descri√ß√£o:** Abordagem baseada em teoria dos jogos para explicar a sa√≠da de qualquer modelo de machine learning. SHAP (SHapley Additive exPlanations) √© uma abordagem baseada em teoria dos jogos para explicar a sa√≠da de qualquer modelo de machine learning.

**Conceitos Fundamentais:**
- **Shapley Values:** Valores de Shapley da teoria dos jogos cooperativos
- **Additive Feature Attribution:** Atribui√ß√£o aditiva de features
- **Model-Agnostic:** Funciona com qualquer modelo

**Tipos de Explainers:**
- **TreeExplainer:** Para modelos baseados em √°rvores (XGBoost, LightGBM, CatBoost)
- **DeepExplainer:** Para redes neurais profundas
- **KernelExplainer:** Model-agnostic, baseado em LIME
- **LinearExplainer:** Para modelos lineares

**Aplica√ß√µes:**
- Explicabilidade de modelos
- Feature selection baseada em import√¢ncia
- Debugging de modelos
- Interpreta√ß√£o de predi√ß√µes

**Visualiza√ß√µes:**
- Summary plots
- Dependence plots
- Force plots
- Waterfall plots

---

## Redu√ß√£o de Dimensionalidade

### PCA, t-SNE, UMAP
- **URL:** [https://medium.com/@aastha.code/dimensionality-reduction-pca-t-sne-and-umap-41d499da2df2](https://medium.com/@aastha.code/dimensionality-reduction-pca-t-sne-and-umap-41d499da2df2)
- **Tipo:** T√©cnicas
- **Descri√ß√£o:** T√©cnicas de redu√ß√£o de dimensionalidade para visualiza√ß√£o e pr√©-processamento de dados.

### Principal Component Analysis (PCA)
**Descri√ß√£o:** T√©cnica linear de redu√ß√£o de dimensionalidade que encontra as dire√ß√µes de m√°xima vari√¢ncia nos dados.

**Caracter√≠sticas:**
- M√©todo linear
- Preserva vari√¢ncia global
- R√°pido e eficiente
- Determin√≠stico

**Quando Usar:**
- Dados com rela√ß√µes lineares
- Pr√©-processamento para ML
- Redu√ß√£o de ru√≠do
- Compress√£o de dados

**Implementa√ß√£o (scikit-learn):**
```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)
```

### t-SNE (t-Distributed Stochastic Neighbor Embedding)
**Descri√ß√£o:** T√©cnica n√£o-linear de redu√ß√£o de dimensionalidade especialmente adequada para visualiza√ß√£o de dados de alta dimens√£o.

**Caracter√≠sticas:**
- M√©todo n√£o-linear
- Preserva estrutura local
- Excelente para visualiza√ß√£o
- Estoc√°stico (resultados variam)

**Quando Usar:**
- Visualiza√ß√£o de dados
- Explora√ß√£o de clusters
- Dados com estrutura n√£o-linear

**Limita√ß√µes:**
- Lento para grandes datasets
- N√£o preserva dist√¢ncias globais
- N√£o determin√≠stico

**Implementa√ß√£o (scikit-learn):**
```python
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, perplexity=30)
X_embedded = tsne.fit_transform(X)
```

### UMAP (Uniform Manifold Approximation and Projection)
**Descri√ß√£o:** T√©cnica moderna de redu√ß√£o de dimensionalidade que preserva tanto estrutura local quanto global.

**Caracter√≠sticas:**
- M√©todo n√£o-linear
- Preserva estrutura local e global
- Mais r√°pido que t-SNE
- Melhor escalabilidade

**Vantagens sobre t-SNE:**
- Mais r√°pido
- Preserva estrutura global
- Melhor para grandes datasets
- Pode ser usado para transforma√ß√£o de novos dados

**Quando Usar:**
- Visualiza√ß√£o de grandes datasets
- Preserva√ß√£o de estrutura global
- Clustering
- Pr√©-processamento para ML

**Implementa√ß√£o (umap-learn):**
```python
import umap

reducer = umap.UMAP(n_components=2)
X_embedded = reducer.fit_transform(X)
```

### Compara√ß√£o: PCA vs t-SNE vs UMAP

| Caracter√≠stica | PCA | t-SNE | UMAP |
|---|---|---|---|
| Linearidade | Linear | N√£o-linear | N√£o-linear |
| Velocidade | R√°pido | Lento | M√©dio |
| Estrutura Local | N√£o | Sim | Sim |
| Estrutura Global | Sim | N√£o | Sim |
| Determin√≠stico | Sim | N√£o | N√£o |
| Escalabilidade | Excelente | Ruim | Boa |
| Novos Dados | Sim | N√£o | Sim |

---

## Feature Importance

### XGBoost Feature Importance
- **URL:** [https://www.machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/](https://www.machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/)
- **Tipo:** T√©cnica
- **Descri√ß√£o:** Como estimar a import√¢ncia de features para um problema de modelagem preditiva usando XGBoost.

**Tipos de Feature Importance no XGBoost:**

1. **Weight (Frequency):**
   - N√∫mero de vezes que uma feature aparece em uma √°rvore
   - M√©trica padr√£o

2. **Gain:**
   - Melhoria m√©dia de ganho quando a feature √© usada em splits
   - Considera a qualidade dos splits

3. **Cover:**
   - N√∫mero m√©dio de observa√ß√µes afetadas pelos splits usando a feature
   - Considera a quantidade de dados

**Implementa√ß√£o:**
```python
from xgboost import XGBClassifier
import matplotlib.pyplot as plt

# Treinar modelo
model = XGBClassifier()
model.fit(X_train, y_train)

# Plot feature importance
plt.figure(figsize=(10, 8))
xgb.plot_importance(model, importance_type='gain')
plt.show()

# Obter import√¢ncias
importances = model.feature_importances_
```

**Aplica√ß√µes:**
- Feature selection
- Compreens√£o do modelo
- Debugging
- Redu√ß√£o de dimensionalidade

---

## Conceitos Fundamentais

### O que √© Feature Engineering?

Feature engineering √© o processo de usar conhecimento do dom√≠nio para criar features (vari√°veis) que tornam os algoritmos de machine learning mais eficazes. √â frequentemente considerado a parte mais importante e demorada de um projeto de ML.

### Tipos de Feature Engineering:

1. **Feature Extraction:**
   - Criar novas features a partir de dados brutos
   - Exemplo: Extrair dia da semana de uma data

2. **Feature Transformation:**
   - Transformar features existentes
   - Exemplo: Logaritmo, normaliza√ß√£o, padroniza√ß√£o

3. **Feature Selection:**
   - Selecionar as features mais relevantes
   - Exemplo: Remover features com baixa vari√¢ncia

4. **Feature Construction:**
   - Criar features atrav√©s de combina√ß√µes
   - Exemplo: Intera√ß√µes entre features

### Pipeline T√≠pico de Feature Engineering:

1. **An√°lise Explorat√≥ria de Dados (EDA)**
   - Entender os dados
   - Identificar padr√µes
   - Detectar anomalias

2. **Tratamento de Dados Faltantes**
   - Imputa√ß√£o
   - Remo√ß√£o
   - Cria√ß√£o de flags

3. **Codifica√ß√£o de Vari√°veis Categ√≥ricas**
   - One-Hot Encoding
   - Label Encoding
   - Target Encoding

4. **Transforma√ß√£o de Features**
   - Normaliza√ß√£o
   - Padroniza√ß√£o
   - Transforma√ß√µes matem√°ticas

5. **Cria√ß√£o de Novas Features**
   - Features de dom√≠nio
   - Agrega√ß√µes
   - Intera√ß√µes

6. **Sele√ß√£o de Features**
   - Baseada em import√¢ncia
   - Baseada em correla√ß√£o
   - M√©todos wrapper

7. **Redu√ß√£o de Dimensionalidade**
   - PCA
   - t-SNE
   - UMAP

---

## Melhores Pr√°ticas

### 1. Compreenda o Dom√≠nio
- Conhecimento do dom√≠nio √© crucial
- Consulte especialistas
- Pesquise sobre o problema

### 2. Comece Simples
- Baseline com features b√°sicas
- Adicione complexidade gradualmente
- Me√ßa o impacto de cada feature

### 3. Use Pipelines
- scikit-learn Pipelines
- Evite data leakage
- Facilita reprodutibilidade

### 4. Valide Corretamente
- Use cross-validation
- Separe train/validation/test
- Cuidado com temporal leakage

### 5. Documente Tudo
- Registre transforma√ß√µes
- Explique features criadas
- Mantenha c√≥digo organizado

### 6. Automatize Quando Poss√≠vel
- Use Featuretools
- Scripts reutiliz√°veis
- Versionamento de features

---

## Ferramentas Complementares

### scikit-learn Feature Selection
- **URL:** [https://scikit-learn.org/stable/modules/feature_selection.html](https://scikit-learn.org/stable/modules/feature_selection.html)
- **M√©todos:**
  - VarianceThreshold
  - SelectKBest
  - SelectPercentile
  - RFE (Recursive Feature Elimination)
  - SelectFromModel

### Category Encoders
- **URL:** [https://contrib.scikit-learn.org/category_encoders/](https://contrib.scikit-learn.org/category_encoders/)
- **Encoders:**
  - One-Hot Encoding
  - Target Encoding
  - Binary Encoding
  - Hash Encoding
  - Leave-One-Out Encoding

---

## Estat√≠sticas

- **Total de Recursos:** 6
- **Bibliotecas:** 3
- **T√©cnicas:** 3
- **M√©todos de Redu√ß√£o:** 3

---

## Refer√™ncias

1. scikit-learn Documentation
2. Feature-engine GitHub
3. Featuretools Documentation
4. SHAP GitHub Repository
5. Machine Learning Mastery
6. Medium Articles on Dimensionality Reduction

---

**√öltima Atualiza√ß√£o:** 30 de Outubro de 2025  
**Mantido por:** Manus AI
